# Kafka CLI를 이용하여 운영하기 

## kafka docker-compose 로 설치하기 

- 우선 kafka 를 local에 설치하자. 
- [02.kafka_install_docker_compose](02.kafka_install_docker_compose.md) 를 참조하자. 

- 혹은 아래와 같이 docker-compose.yaml 파일을 만들고 실행해도 된다.

```yaml
---
version: '2'

services:
  zookeeper-1:
    image: confluentinc/cp-zookeeper:latest
    hostname: zookeeper
    container_name: zookeeper-1
    ports:
      - "22181:22181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 22181
      ZOOKEEPER_TICK_TIME: 2000

  kafka-1:
    image: confluentinc/cp-kafka:latest
    hostname: broker
    container_name: kafka-1
    depends_on:
      - zookeeper-1
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper-1:22181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-1:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0


```

- 그리고 다음 명령어로 실행하자. 

```go
docker-compose up -d
```

## TOPIC 생성하기. 

- 우선 메시지를 주고 받기 위해서는 TOPIC를 생성해야한다. 

```go
docker-compose exec kafka-1 kafka-topics --create --topic orders --bootstrap-server kafka-1:29092

Created topic orders.
```

- 위와 같이 order라는 이름의 토픽이 생성 되었다. 

## consumer 시작하기. 

- 이제 docker-compose 의 컨테이너 내부로 들어가자. 
- 컨테이너 내부의 셀을 실행하기 위해서 다음과 같이 실행할 수 있다. 

```go
docker-compose exec kafka-1 bash

[appuser@broker ~]$ kafka-console-consumer --topic orders --bootstrap-server kafka-1:29092
```

## producer 시작하고 메시지 전송하기 

- 이제 메시지를 전송하자. 
- 그러기 위해서 producer 커맨드를 실행하자. 

```go
docker-compose exec kafka-1 bash

[appuser@broker ~]$ kafka-console-producer --topic orders --bootstrap-server kafka-1:29092
>>test
>>Hello
>test
>send message
```

- 위와 같이 메시지를 전송하면 컨슈머에서 다음과 같이 메시지를 받게 된다. 

```go
[appuser@broker ~]$ kafka-console-consumer --topic orders --bootstrap-server kafka-1:29092
test
Hello
test
send message
```

## 컨슈머 실행시 이전 레코드 모두 가져오기 

- 컨슈머를 실행하면 현재 오프셋을 수신한다. 그러나 이전의 모든 오프셋을 수신해야한다면 --from-beginning 옵션을 통해서 토픽의 모든 메시지를 가져오도록 해야한다. 

```go
[appuser@broker ~]kafka-console-consumer --topic orders --bootstrap-server kafka-1:29092 --from-beginning

test
Hello
test
send message
```

- 위와 같이 --from-beginning 을 이용하면 이전 토픽이 모두 출력된다. 

## 파티션 키 이용하기 

- kafka에서는 기본적으로 키를 사용하는 경우 키를 해시하고, 특정 파티션으로 메시지가 전달된다. 
- 키를 사용하지 않으면 토픽을 라운드 로빈으로 분배 되게 된다. 
- 프로듀서를 기동할때 키 설정을 이용할 수 있다. 

```go
[appuser@broker ~]$ kafka-console-producer --topic orders --bootstrap-server kafka-1:29092 --property parse.key=true --property key.separator=":"

>key1:hello world
>key2:produce with key
```

- 위와 같이 --property parse.key=true 를 설정하여 키를 이용하겠다고 지정한다. 
- --property key.separator=":" 라고 하면 키와 값을 ':' 으로 구분한다는 의미이다. key:value 형태로 메시지를 입력하면 된다. 
- key1:hello world, key2:produce with key 으로 메시지를 보냈다. 

- 위와 같이 수행하면 컨슈머는 다음과 같이 출력된다. 즉 키가 제거된 값만 출려된다. 

```go
hello world
produce with key
```

## 컨슈머에서 키/값 정보를 그대로 보여주기 

- 컨슈머에서 키와 값을 출력해 주고자 한다면 print.key와 key.separator 옵션을 이용하여 출력해  줄 수 있다. 

```go
[appuser@broker ~]$ kafka-console-consumer --topic orders --bootstrap-server kafka-1:29092 --from-beginning --property print.key=true --property key.separator=">"

null>test
null>Hello
null>test
null>send message
key1>hello world
key2>produce with key
```

- 위와 같이 print.key=true 를 통해서 키를 출력하겠다라고 지정했다. 
- key.separator=">" 으로 key>value 형태로 보여주도록 설정했다. 
- 참고 --from-beginning 을 이용했으므로 이전에 키 없이 보냈던 데이터는 null>value 형태로 출력되었다. 


