# Kafka Install Broker on Kubrernetes 

- Kafka를 Kubernetes에 설치하기 위해서 Strimzi 라는 도구를 이용할 수 있다. 
- 다음 내용의 원본은 Strimzi: https://strimzi.io/docs/operators/latest/quickstart.html 에서 확인할 수 있다. 

# Strimzi Quick Start guide 

## 1. Overview of Strimzi 

- Strimzi 은 Kubernetes 클러스터에서 Apache Kafka 수행중인 프로세스의 프로세스를 단순화 한다. 

- 이 가이드는 Strimzi 의 환경을 평가하기 위한 지침을 제공한다. 
- 이 단계에서는 Strimzi 배포를 가능한 빨리 시작하고 실행하는 방법을 설명합니다. 

- Strimzi를 사용하기 전에 해당 기능과 사용 방법을 이해하는 것이 좋다. 
- 이 장에서는 Kafka의 핵심 개념 중 일부를 소개하고 Strimzi 연산자에 대한 간략한 개요도 제공한다. 

- 운영자는 패키징 방법, 배포, 쿠버네티스 어플리케이션 관리를 수행한다. 
- Strimzi 오퍼레이터들은 Kubernetes 기능적으로 확장하고, Kafka 배포와 관련된 일반적이고 복잡한 작업을 자동화 한다. 
- Kafka 작업에 대한 지식을 코드로 구현함으로써 Kafka 관리 작업이 간소화 되고 수동 개입이 덜 필요하다. 

### 1.1 kafka capabilities 

- Kafka의 기본 데이터 스트림 처리 기능 및 구성 요서 아키텍처는 다음을 제공할 수 있다. 
  - 마이크로서비스 그리고 다른 어플리케이션은 극단적으로 높은 처리량과 낮은 응답속도를 위해 데이털르 공유한다. 
  - 메시지 순서를 보장한다. 
  - 메시지 rewind/replay 를 데이터 스토리지로 부터 어플리케이션 상태를 다시 구성할 수 있다. 
  - 메시지 컴팩션은 키/값 로그를 이용할때 오래된 레코드를 제거한다. 
  - 클러스터 설정에 수평 활장성이 있다. 
  - 장애 대응을 컨트롤 하기 위해서 데이터의 복제 
  - 즉시 접근하기 위한 데이터의 높은 볼륨을 유지한다. 

### 1.2 Kafka use cases 

- Kafka의 능력은 다음에 적당하다. 
  - 이벤트 드리븐 아키텍처 
  - 이벤트 소싱을 통해 변경된 어플리케이션의 상태를 이벤트 로그로 저장한다. 
  - 메시지 브로커링 
  - 웹사이트 활동 트래킹 
  - 메트릭을 통한 조작, 모니터링 
  - 로그 컬렉션과 집계 
  - 분산 시스템에 대한 커밋 로그 
  - 스트림 프로세싱을 통한 어플리케이션은 실시간 데이터 처리를 할 수 있다. 


### 1.3 How Strimzi supports Kafka 

- Strimzi 는 컨테이너 이미지를 제공하고 Kubernetes에서 수행되는 Kafka의 오퍼레이터를 수행한다. 
- Strimzi 오퍼레이터들은 Strimzi의 수행하는 기본이 된다. 
- 오퍼레이터는 Strimzi 로 Kafka를 효과적으로 관리하기 위해 전문적인 운영 지식으로 특별히 제작되어 있다. 

- 오퍼레이터들은 단순하게 처리를 다음과 같이 수행된다. 
  - Kafka cluster의 배포, 수행 
  - Kafka 컴포넌트의 배포, 수행 
  - Kafka에 접속하기 위한 설정 
  - Kafka 에 보안 접속 
  - Kafka 업그레이딩 
  - 브로커 관리 
  - 토픽의 생성, 관리 
  - 사용자의 생성, 관리 

### 1.4 Operators 

- Strimzi 는 Kafka 클러스터를 Kubernetes 클러스터에 관리하기 위한 오퍼레이터를 제공한다. 

- Cluster Operator 
  - apache kafka 클러스터 배포와 관리, Kafka Connect, Kafka MirrorMaker, Kafka Bridge, Kafka Explorer, Cruise Control 그리고 엔터티 오퍼레이터이다. 
- Entity Operator 
  - Topic Operator와 User Operator 와 통합되어 있다. 
- Topic Operator 
  - Kafka topics 관리 
- User Operator 
  - Kafka user 관리 

- 클러스터 오퍼레이터는 Topic Operator 그리고 User Operator를 배포할 수 있으며 이는 Kafka cluster에 동일한 시간동안 Entity Operator 설정의 부분이 된다. 

- Operators within the Strimzi architecture 

![architecture](https://strimzi.io/docs/operators/latest/images/operators.png)

### 1.5 Document Conventions 

- ***User-replaced value***

- user-replaced 값은 replaceables로 알려 져 있다. 이는 이탤릭체로 angle bracket(<>)로 보여진다. 
- Underscore(_) 들은 먹티 워드 값으로 사용된다. 만약 코더 혹은 커맨더 값을 참조하며 monospace가 사용된다. 

- 예를 들어 다음 코드에서 <my_namespace> 는 namespace의 이름과 함께 겨체할 수 있다.

```go
sed -i 's/namespace: .*/namespace: <my_namespace>/' install/cluster-operator/*RoleBinding*.yaml
```

## 2. Evaluate Strimzi 

- 이 장의 절차는 Strimzi의 기능을 평가하는 빠른 방법을 제공한다. 

- Strimzi 설치를 위해 다음 절차를 따르고, 전송하고, 메시지를 토픽으로 수신할 수 있다. 
  - 사전에 필요한 필요사항을 보장한다. 
  - Minikube 를 인스톨하고 시작한다. 
  - Strimzi 설치 
  - kafka cluster 생성 
  - Kafka cluster 접근으로 메시지를 송신, 수신한다. 

### 2.1 Prerequisites 

- [Install and start Minikube](https://kubernetes.io/docs/tasks/tools/install-minikube/)
- Strimzi [Github](https://github.com/strimzi/strimzi-kafka-operator/releases) 에 접속할 필요가 있다. 

### 2.2 Downloading Strimzi 

- Strimzi를 설치하는 데 필요한 리소스 및 아티팩트와 구성 예제는 ZIP 파일로 제공된다. 

***Procedure***

1. strimzi-x.y.z.zip 파일을 [GitHub](https://github.com/strimzi/strimzi-kafka-operator/releases) 에서 다운로드 받는다. 
2. 특정 디렉토리에 파일을 해제한다. 
   1. Windows혹은 Mac : 이는 Zip파일에서 더블 체크하여 ZIP 아카이브의 내용을 해제한다. 
   2. Linux: 타겟 머신에서 터미널을 연다 그리고 ZIP 파일을 다운로드한 위치로 이동한다. 

- ZIP 파일을 다음 커맨드로 해제한다. 

```go
unzip strimzi-xyz.zip
```

### 2.3 Installing Strimzi 

- [download files](https://strimzi.io/docs/operators/latest/quickstart.html#proc-product-downloads-str) 를 이용하여 Strimzi 를 Custom Resource Definitions(CRDs)와 RBAC 설정을 설치를 위해 필요하다. 

- 이 태스크에서 배포할 namespace를 생성하자. 그리고 기능을 분할하기 위해서 namespace 를 이용한다. 

***Prerequisites***

- Kubernetes 계정은 클러서트 admin 크레덴셜을 위해 피룡하다. 

***Procedure***

1. Kubernetes 클러스터에 로그인은 클러스터 admin 권한이 필요하다. 
2. Strimzi Kafka Cluster Operator에 대한 kafka namespace를 생성하자. 그리고

```go
kubectl create ns kafka
```

3. kafka namespace 참조를 위해 설치파일을 변경한다. 이는 Strimzi Kafka Cluster Operator에 설치되어 있다. 

노트: 기본적으로 파일은 myproject namespace 에 동작한다. 

- Linux 에서 이용 

```go
sed -i 's/namespace: .*/namespace: kafka/' install/cluster-operator/*RoleBinding*.yaml
```

- Mac에서 이용한다. 

```go
sed -i '' 's/namespace: .*/namespace: kafka/' install/cluster-operator/*RoleBinding*.yaml
```

4. my-kafka-project namespace를 생성하여 이는 Kafka cluster 에 설치될 것이다. 

```go
kubectl create ns my-kafka-project
```

5. install/cluster-operator/060-Deployment-strimzi-cluster-operator.yaml 파일을 수정하자. 그리고 STRIMZI_NAMESPACE 환경 변수의 my-kafka-project 네임스페이스를 설정한다. 

```go
# ...
env:
- name: STRIMZI_NAMESPACE
  value: my-kafka-project
# ...
```

6. DRD를 배포하고, role 비잔 엑세스 컨트롤 (RBAC) 리소스를 CRD 에 접근한다. 

```go
kubectl create -f install/cluster-operator/ -n kafka
```

7. 클러슽 운영자에게 my-kafka-project 네임스페이스를 볼 수 있는 권한을 부여한다. 

```go
kubectl create -f install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml -n my-kafka-project
```

```go
kubectl create -f install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml -n my-kafka-project
```

- 커맨드는 롤바인딩을 생성한다. 이는 클러스터 오퍼레이터에 대한 퍼미션을 생성하고, Kafka 클러스터에 접근하도록 한다. 

### 2.4 Creating a cluster 

- Strimzi 설치되고, Kafka cluster 생성하고, topic 으로 cluster에 지정된다. 

- cluster를 생성할때 Cluster Operator 는 새로운 Kafka 리소스를 감시한다. 

***Prerequisites***

- Kafka cluster에 대해서 Cluster Operator가 배포되었음을 확인하자. 
- 토픽을 위해서는 Kafka cluster가 수행되어 있어야한다. 

***Procedure***

1. Kubernetes cluster에 non-privileged user로 로그인한다. 
2. my-cluster Kafka 클러스터를 하나의 ZooKeeper와 하나의 Kafka broker로 생성한다. 
   1. presistent-claim 스토리지 이용 
   2. Kubernetes 클러스터의 Kafka cluster 외부로 드러내기 위해서 외부 리스터를 nodeport를 통해 지정한다. 

```go
cat << EOF | kubectl create -n my-kafka-project -f -
apiVersion: kafka.strimzi.io/v1beta2
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    replicas: 1
    listeners:
      - name: plain
        port: 9092
        type: internal
        tls: false
      - name: tls
        port: 9093
        type: internal
        tls: true
        authentication:
          type: tls
      - name: external
        port: 9094
        type: nodeport
        tls: false
    storage:
      type: jbod
      volumes:
      - id: 0
        type: persistent-claim
        size: 100Gi
        deleteClaim: false
    config:
      offsets.topic.replication.factor: 1
      transaction.state.log.replication.factor: 1
      transaction.state.log.min.isr: 1
      default.replication.factor: 1
      min.insync.replicas: 1
  zookeeper:
    replicas: 1
    storage:
      type: persistent-claim
      size: 100Gi
      deleteClaim: false
  entityOperator:
    topicOperator: {}
    userOperator: {}
EOF
```

3. 클러스터가 배포되기 위해서 대기한다. 

```go
kubectl wait kafka/my-cluster --for=condition=Ready --timeout=300s -n my-kafka-project

```

4. 클러스터가 준비되면 토픽을 생성하여 외부 클라이언트로 부터 퍼블리시, 서브스크라이브 할 토픽을 생성한다. 

- my-topic 커스텀 리소스를 3개의 파티션 그리고 my-cluster Kafka cluster에 복제 계수를 1개 설정한다. 

```go
cat << EOF | kubectl create -n my-kafka-project -f -
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaTopic
metadata:
  name: my-topic
  labels:
    strimzi.io/cluster: "my-cluster"
spec:
  partitions: 3
  replicas: 1
EOF
```

## 2.5 Sending and receiving message from topic 

- 클러스터 외부에서 my-topic 로 메시지를 보내고 받아 Strimzi 설치를 테스트할 수 있다. 
- kafka 프로듀서를 실행하기 위해서 터미널을 이용하고 로컬 머신에서 컨슈머를 수행한다. 

***Prerequisites***

- Strimzi 보장은 Kubernetes cluster에 설치되어 있다. 
- ZooKeeper와 Kafka 는 반드시 메시지를 전송하고 수신할 수 있어야한다. 

***Procedure***

1. 최종 Kafka 바이너리를 다운로드 하고 로컬 머신에서 인스톨을 수행하자.
http://kafka.apache.org/
2. 부트스트랩 서비스의 포트를 찾는다. 
```go
kubectl get service my-cluster-kafka-external-bootstrap -n my-kafka-project -o=jsonpath='{.spec.ports[0].nodePort}{"\n"}'

```
3. Minikube node의 IP 주소를 찾는다. 
```go
kubectl get nodes --output=jsonpath='{range .items[*]}{.status.addresses[?(@.type=="InternalIP")].address}{"\n"}{end}'

```
4. 터미널을 열고, Kafka 콘솔 프로듀서를 시작하고 토픽 my-topic 을 생성한다. 
```go
bin/kafka-console-producer.sh --broker-list <node-address>:_<node-port>_ --topic my-topic

```
5. 프로듀서가 수행하고 있는 콘솔에 메시지를 타입핑한다. 
6. 새로운 터미널을 탭이나 윈도우를 연다. 그리고 메시지 수신을 위한 컨슈머를 시작한다. 
```go
bin/kafka-console-consumer.sh --bootstrap-server <node-address>:_<node-port>_ --topic my-topic --from-beginning

```
7. 컨수머 콘솔에서 들어오는 메시지를 확인한다. 
8. Ctrl+C 를 누르고 Kafka console producer과 consumer를 종료한다. 

