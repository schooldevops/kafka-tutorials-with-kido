---
version: '3.8'
services:
  zookeeper-1:
    image: confluentinc/cp-zookeeper:5.5.1
    ports:
      - '32181:32181'
    environment:
      ZOOKEEPER_CLIENT_PORT: 32181
      ZOOKEEPER_TICK_TIME: 2000


  kafka-1:
    image: confluentinc/cp-kafka:5.5.1
    ports:
      - '9092:9092'
    depends_on:
      - zookeeper-1
    volumes:
      - ${PWD}/:/etc/tutorial/      
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper-1:32181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka-1:29092,EXTERNAL://localhost:9092
      KAFKA_DEFAULT_REPLICATION_FACTOR: 2
      KAFKA_NUM_PARTITIONS: 3


  kafka-2:
    image: confluentinc/cp-kafka:5.5.1
    ports:
      - '9093:9093'
    depends_on:
      - zookeeper-1
    volumes:
      - ${PWD}/:/etc/tutorial/ 
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_ZOOKEEPER_CONNECT: zookeeper-1:32181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka-2:29093,EXTERNAL://localhost:9093
      KAFKA_DEFAULT_REPLICATION_FACTOR: 2
      KAFKA_NUM_PARTITIONS: 3
    

  kafka-3:
    image: confluentinc/cp-kafka:5.5.1
    ports:
      - '9094:9094'
    depends_on:
      - zookeeper-1
    volumes:
      - ${PWD}/:/etc/tutorial/ 
    environment:
      KAFKA_BROKER_ID: 3
      KAFKA_ZOOKEEPER_CONNECT: zookeeper-1:32181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka-3:29094,EXTERNAL://localhost:9094
      KAFKA_DEFAULT_REPLICATION_FACTOR: 2
      KAFKA_NUM_PARTITIONS: 3

  schema-registry:
    image: confluentinc/cp-schema-registry:latest
    platform: linux/x86_64
    environment:
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: "kafka-1:29092,kafka-2:29093,kafka-3:29094"
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
    depends_on:
      - zookeeper-1
      - kafka-1
      - kafka-2
      - kafka-3
    ports:
      - '8081:8081'

  connect:
    hostname: connect
    image: confluentinc/cp-kafka-connect-base:latest
    platform: linux/x86_64
    depends_on:
      - schema-registry
      - kafka-1
      - kafka-2
      - kafka-3
    ports:
      - '8083:8083'
    environment:
      CONNECT_BOOTSTRAP_SERVERS: "kafka-1:29092,kafka-2:29093,kafka-3:29094"
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: kafka-connect
      CONNECT_CONFIG_STORAGE_TOPIC: _connect-configs
      CONNECT_OFFSET_STORAGE_TOPIC: _connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: _connect-status
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: 'true'
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'
      CONNECT_REST_ADVERTISED_HOST_NAME: "kafka-connect"
      CONNECT_LOG4J_APPENDER_STDOUT_LAYOUT_CONVERSIONPATTERN: "[%d] %p %X{connector.context}%m (%c:%L)%n"
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_PLUGIN_PATH: /usr/share/confluent-hub-components
    volumes:
      - ./connector_config:/connector_config
      - ./tools/db_connector:/usr/share/java/kafka-connect-jdbc
    command:
      - bash
      - -c
      - |
         echo "Installing Connectors"
         confluent-hub install --no-prompt neo4j/kafka-connect-neo4j:latest
         confluent-hub install --no-prompt confluentinc/kafka-connect-jdbc:latest
         cp /usr/share/java/kafka-connect-jdbc/mysql-connector-java-8.0.27.jar /usr/share/confluent-hub-components/confluentinc-kafka-connect-jdbc/lib/
         #
         echo "Launching Kafka Connect worker"
         /etc/confluent/docker/run &
         #
         # Wait for Kafka Connect listener
         echo "Waiting for Kafka Connect to start listening on localhost"
         while : ; do
           curl_status=$$(curl -s -o /dev/null -w %{http_code} http://localhost:8083/connectors)
           echo -e $$(date) " Kafka Connect listener HTTP state: " $$curl_status " (waiting for 200)"
           if [ $$curl_status -eq 200 ] ; then
             break
           fi
           sleep 5 
         done
         echo -e "\n--\n+> Creating Data Generator source"
         cd /connector_config
         curl -i -X PUT -H Content-Type:application/json http://localhost:8083/connectors/source-mysql-user-00/config -d@mysql-config-source.json
         curl -i -X PUT -H Content-Type:application/json http://localhost:8083/connectors/sink-mysql-user-00/config -d@mysql-config-sink.json
         #  curl -i -X PUT -H Content-Type:application/json http://localhost:8083/connectors/sink-neo4j-user-00/config -d@neo4j-config.json
         #
         sleep infinity      

  neo4j:
    image: neo4j:latest
    container_name: neo4j
    ports:
      - "7474:7474"
      - "7687:7687"
    environment:
      NEO4J_AUTH: neo4j/connect
      NEO4J_dbms_memory_heap_max__size: 2G
      NEO4J_ACCEPT_LICENSE_AGREEMENT: 'yes'
      NEO4J_dbms_directories_import: "/"
      NEO4JLABS_PLUGINS: '["apoc"]'
    volumes:
      - ./neo4j-init-files:/var/lib/neo4j/conf             

  mysql:
    # *-----------------------------*
    # To connect to the DB:
    #   docker exec -it mysql bash -c 'mysql -u root -p$MYSQL_ROOT_PASSWORD demo'
    # *-----------------------------*
    platform: linux/x86_64
    image: mysql/mysql-server:8.0.23
    container_name: mysql
    ports:
      - 3306:3306
    environment:
      - MYSQL_ROOT_PASSWORD=1234
      - MYSQL_USER=user
      - MYSQL_PASSWORD=1234
    volumes:
      - ./mysql-init-files:/docker-entrypoint-initdb.d


# Initial Kafka
# - Create Topic to use 'kafka connector'
  init-kafka:
    image: confluentinc/cp-kafka:latest
    depends_on:
      - schema-registry
      - kafka-1
      - kafka-2
      - kafka-3
    entrypoint: [ '/bin/sh', '-c' ]
    command: |
      "
      # blocks until kafka is reachable
      kafka-topics --bootstrap-server kafka-1:29092,kafka-2:29093,kafka-3:29094 --list 
      echo -e 'Deleting kafka topics'
      kafka-topics --bootstrap-server kafka-1:29092,kafka-2:29093,kafka-3:29094 --delete --topic jdbc-connector-user
      kafka-topics --bootstrap-server kafka-1:29092,kafka-2:29093,kafka-3:29094 --delete --topic jdbc-connector-group
      kafka-topics --bootstrap-server kafka-1:29092,kafka-2:29093,kafka-3:29094 --delete --topic jdbc-connector-group_user
      kafka-topics --bootstrap-server kafka-1:29092,kafka-2:29093,kafka-3:29094 --delete --topic jdbc-connector-role
      kafka-topics --bootstrap-server kafka-1:29092,kafka-2:29093,kafka-3:29094 --delete --topic jdbc-connector-user_role
      kafka-topics --bootstrap-server kafka-1:29092,kafka-2:29093,kafka-3:29094 --delete --topic jdbc-connector-group_role
      kafka-topics --bootstrap-server kafka-1:29092,kafka-2:29093,kafka-3:29094 --delete --topic jdbc-connector-policy
      kafka-topics --bootstrap-server kafka-1:29092,kafka-2:29093,kafka-3:29094 --delete --topic jdbc-connector-role_policy
      kafka-topics --bootstrap-server kafka-1:29092,kafka-2:29093,kafka-3:29094 --delete --topic jdbc-connector-user_policy
      kafka-topics --bootstrap-server kafka-1:29092,kafka-2:29093,kafka-3:29094 --delete --topic jdbc-connector-group_policy
      echo -e 'Creating kafka topics'
      kafka-topics --bootstrap-server kafka-1:29092,kafka-2:29093,kafka-3:29094 --create --topic jdbc-connector-user
      kafka-topics --bootstrap-server kafka-1:29092,kafka-2:29093,kafka-3:29094 --create --topic jdbc-connector-group
      kafka-topics --bootstrap-server kafka-1:29092,kafka-2:29093,kafka-3:29094 --create --topic jdbc-connector-group_user
      kafka-topics --bootstrap-server kafka-1:29092,kafka-2:29093,kafka-3:29094 --create --topic jdbc-connector-role
      kafka-topics --bootstrap-server kafka-1:29092,kafka-2:29093,kafka-3:29094 --create --topic jdbc-connector-user_role
      kafka-topics --bootstrap-server kafka-1:29092,kafka-2:29093,kafka-3:29094 --create --topic jdbc-connector-group_role
      kafka-topics --bootstrap-server kafka-1:29092,kafka-2:29093,kafka-3:29094 --create --topic jdbc-connector-policy
      kafka-topics --bootstrap-server kafka-1:29092,kafka-2:29093,kafka-3:29094 --create --topic jdbc-connector-role_policy
      kafka-topics --bootstrap-server kafka-1:29092,kafka-2:29093,kafka-3:29094 --create --topic jdbc-connector-user_policy
      kafka-topics --bootstrap-server kafka-1:29092,kafka-2:29093,kafka-3:29094 --create --topic jdbc-connector-group_policy
      echo -e 'Successfully created the following topics:'
      kafka-topics --bootstrap-server kafka-1:29092,kafka-2:29093,kafka-3:29094 --list
      sleep infinity
      "
  kafka-ui:
    image: provectuslabs/kafka-ui
    container_name: kafka-ui
    depends_on:
      - init-kafka
    ports:
      - "8989:8080"
    restart: always
    environment:
      - KAFKA_CLUSTERS_0_NAME=local
      # - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka-1:29092
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka-1:29092,kafka-2:29093,kafka-3:29094
      # - KAFKA_CLUSTERS_0_ZOOKEEPER=zookeeper-1:22181,zookeeper-2:32181,zookeeper-3:42181
      - KAFKA_CLUSTERS_0_ZOOKEEPER=zookeeper-1:22181      