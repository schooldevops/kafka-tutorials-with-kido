# Kafka Deserialize 사용 및 SchemaRegistry 이용하기 

- kafka는 브로커에 메시지를 퍼블리시하고, 컨슘할때 메시지를 Serialize/Deserialize 한다. 
- 또한 스키마를 Schema Registry 에 등록하여, 전달되는 메시지의 스키마를 검사하고, Serialize/Deserialize 할 수 있다. 

## docker-compose 를 이용하여 브로커와 스키마 레지스터리 시작하기 

```go
---
version: '2'

services:
  zookeeper-1:
    image: confluentinc/cp-zookeeper:latest
    hostname: zookeeper
    container_name: zookeeper-1
    ports:
      - "22181:22181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 22181
      ZOOKEEPER_TICK_TIME: 2000

  kafka-1:
    image: confluentinc/cp-kafka:latest
    hostname: broker
    container_name: kafka-1
    depends_on:
      - zookeeper-1
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper-1:22181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-1:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0

  schema-registry:
      image: confluentinc/cp-schema-registry:latest
      hostname: schema-registry
      platform: linux/amd64
      container_name: schema-registry
      depends_on:
        - kafka-1
      ports:
        - "8081:8081"
      volumes:
        - ${PWD}/:/etc/tutorial/
      environment:
        SCHEMA_REGISTRY_HOST_NAME: schema-registry
        SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'kafka-1:29092'
        SCHEMA_REGISTRY_LOG4J_ROOT_LOGLEVEL: WARN      
```

## Kafka Topic 생성하기. 

- 이제는 토픽을 생성하자. 

```go
docker-compose exec kafka-1 kafka-topics --create --topic order-avro --bootstrap-server kafka-1:29092

Created topic order-avro.
```

- 위와 같이 order-avro 라는 토픽이 생성 되었다. 

## 스키마 생성하고 레지스터리 등록하기 

- 전달되는 메시지(레코드) 포맷을 컨틀롤 하기 위해서 Schema Registry 를 이용할 것이다 .
- 스키마를 생성하기 위해서 orders-avro-schema.json 파일을 다음과 같이 작성한다. 

```json
{
"type": "record",
"namespace": "io.confluent.tutorial",
"name": "OrderDetail",
"fields": [
    {"name": "number", "type": "long", "doc": "The order number."},
    {"name": "shipping_address", "type": "string", "doc": "The shipping address."},
    {"name": "subtotal", "type": "double", "doc": "The amount without shipping cost and tax."},
    {"name": "shipping_cost", "type": "double", "doc": "The shipping cost."},
    {"name": "tax", "type": "double", "doc": "The applicable tax."},
    {"name": "grand_total", "type": "double", "doc": "The order grand total ."}
    ]
}
```

- 스키마는 JSON으로 생성하며, fields 항목에서 name, type, doc 등으로 스키마 속성을 작성한다. 

## 컨슈머 시작하기 

- 이제 컨슈머를 생성하자. 컨슈머를 생성할때 스키마 레지스터리도 함께 등록한다. 

```go
docker-compose exec schema-registry bash

[appuser@schema-registry ~]$ kafka-avro-console-consumer --topic order-avro --bootstrap-server kafka-1:29092 --property schema.registry.url=http://localhost:8081
```

## 프로듀서 실행하고 레코드 전송하기

- 이제는 프로듀서를 실행하로 레코드를 전송하자. 
- 레코드 전송시 우리가 정의한 스키마에 맞게 전송해야한다. 

```go
docker-compose exec schema-registry bash

[appuser@schema-registry ~]$ kafka-avro-console-producer --topic order-avro --bootstrap-server kafka-1:29092 --property schema.registry.url=http://localhost:8081 --property value.schema="$(< /etc/tutorial/orders-avro-schema.json)"
```

- 실행되면 다음 내용을 입력하고 enter 하자. 

```go
{"number":1,"shipping_address":"ABC Sesame Street,Wichita, KS. 12345","subtotal":110.00,"tax":10.00,"grand_total":120.00,"shipping_cost":0.00}
{"number":2,"shipping_address":"123 Cross Street,Irving, CA. 12345","subtotal":5.00,"tax":0.53,"grand_total":6.53,"shipping_cost":1.00}
{"number":3,"shipping_address":"5014  Pinnickinick Street, Portland, WA. 97205","subtotal":93.45,"tax":9.34,"grand_total":102.79,"shipping_cost":0.00}
{"number":4,"shipping_address":"4082 Elmwood Avenue, Tempe, AX. 85281","subtotal":50.00,"tax":1.00,"grand_total":51.00,"shipping_cost":0.00}
{"number":5,"shipping_address":"123 Cross Street,Irving, CA. 12345","subtotal":33.00,"tax":3.33,"grand_total":38.33,"shipping_cost":2.00}
```

## Key-value 쌍으로 메시지 프로듀싱 하기

```go
kafka-avro-console-producer --topic order-avro --bootstrap-server kafka-1:29092 --property schema.registry.url=http://localhost:8081 --property value.schema="$(< /etc/tutorial/orders-avro-schema.json)"  --property key.serializer=org.apache.kafka.common.serialization.StringSerializer --property parse.key=true --property key.separator=":"
```

- 실행결과 아래와 같다. 

```go
6:{"number":6,"shipping_address":"9182 Shipyard Drive, Raleigh, NC. 27609","subtotal":72.00,"tax":3.00,"grand_total":75.00,"shipping_cost":0.00}
7:{"number":7,"shipping_address":"644 Lagon Street, Chicago, IL. 07712","subtotal":11.00,"tax":1.00,"grand_total":14.00,"shipping_cost":2.00}
```

## Consumer key-value 쌍으로 메시지 프로듀싱 하기 

```go
kafka-avro-console-consumer --topic order-avro --property schema.registry.url=http://localhost:8081 --bootstrap-server kafka-1:29092 --property key.deserializer=org.apache.kafka.common.serialization.StringDeserializer --property print.key=true --property key.separator="-" --from-beginning
```

- 메시지를 수신하면 아래와 같다. 
- 키 값을 주지 않은 것은 null-, 키값을 준 곳은 키-값 의 형태로 노출 되었다.   

```go
null-{"number":1,"shipping_address":"ABC Sesame Street,Wichita, KS. 12345","subtotal":110.0,"shipping_cost":0.0,"tax":10.0,"grand_total":120.0}
null-{"number":2,"shipping_address":"123 Cross Street,Irving, CA. 12345","subtotal":5.0,"shipping_cost":1.0,"tax":0.53,"grand_total":6.53}
6-{"number":6,"shipping_address":"9182 Shipyard Drive, Raleigh, NC. 27609","subtotal":72.0,"shipping_cost":0.0,"tax":3.0,"grand_total":75.0}
7-{"number":7,"shipping_address":"644 Lagon Street, Chicago, IL. 07712","subtotal":11.0,"shipping_cost":2.0,"tax":1.0,"grand_total":14.0}
```