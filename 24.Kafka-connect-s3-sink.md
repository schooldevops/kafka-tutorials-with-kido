# Kafka Connect Basic 

## 개요

- Kafka Connector는 외부 시스템과 kafka 브로커를 연결해주는 프레임워크이다. 
- 데이터베이스, 파일 시스템, noSQL (key-value store, documentdb 등)과 같은 외부 시스템과 연동을 수행할 수 있다. 
- Kafka Connector는 컴포넌트화 되어 바로 사용할 수 있다. 외부 시스템에서 Kafka 토픽으로 부터 데이터를 가져온다.
- 이미 존재하는 커넥터를 이용할 수 있고, 자체 커넥터를 구성할 수 있다. 

- 소스 커넥터
  - 소스 커넥터는 시스템으로 부터 데이터를 수집하고, 소스 시스템은 데이터베이스, 스트림 테이블, 메시지 브로커 등이 있다. 
  - 소스 커넥터는 또한 애플리케이션 서버에서 Kafka 주제로 메트릭을 수집하여 짧은 대기 시간으로 스트림 데이터를 만들 수 있다. 

- 싱크 커넥터
  - 싱크 컨넥터는 Kafka 토픽으로 부터 다른 시스템으로 데이터를 전달한다. 데이터베이스, Hadoop, 등과 같은 데이터저장소로 이관할 수 있다. 

## 지원기능 

- 외부 시스템과 연결 지원 
- 분산 모드, 스탠드 얼론 모드 지원
- REST API 지원 
- 자동 offset 관리 
- 기본적으로 분산, 확장성 지원
- 스트리밍, 배치 통합
- 각 메시지의 변환 지원 

## kafka 설치 

- kafka 설치는 [install-multi-broker](03.kafka_install_multi_broker_docker_compose.md) 참조

## 테스트하기 

- 소스 커넥터
  - 소스 커넥터는 File source connector 를 이용한다. 
- 싱크 커넥터
  - 싱크 커넥터는 S3 sink connector 를 이용한다. 

### Source Connector 설정하기 

- 소스 커넥터를 구성하기 위해서 connector_config/connect-file-source.json 를 다음과 같이 작성한다. 

```go
{
  "connector.class": "FileStreamSource",
  "tasks.max": 1,
  "file": "/sample_data/source.txt",
  "topic": "s3-sink-connector"
}
```

- connector.class: 커넥터의 종유를 나타내며, FileStreamSource로 지정했다. 
- tasks.max: 소스 커넥터를 병렬로 수행할 인스턴스 개수를 나타낸다. 
- topic: 커넥터와 연동할 브로커의 topic을 지정한다. 
- file: 소스 파일을 지정한다. 

<br/>
- source.txt 파일을 다음과 같이 작성하자. 

```go
Hello this is example of connector.
My name is Schooldevops
Apple
Watermelon
Orange
melon
lemon
```

### Sink Connector 설정하기 

- 이제 싱크 커넥터를 만들자. connector_config/connect-s3-sink.json 파일을 생성하고 다음과 같이 작성하자. 

```go
{
    "topics": "s3-sink-connector",
    "tasks.max": 1,
    "connector.class": "io.confluent.connect.s3.S3SinkConnector",
    "key.converter.schemas.enable":"false",
    "value.converter.schemas.enable":"false",
    "key.converter":"org.apache.kafka.connect.storage.StringConverter",
    "value.converter":"org.apache.kafka.connect.json.JsonConverter",
    "format.class": "io.confluent.connect.s3.format.json.JsonFormat",
    "storage.class": "io.confluent.connect.s3.storage.S3Storage",
    "partitioner.class":"io.confluent.connect.storage.partitioner.DefaultPartitioner",
    "flush.size": 3,
    "s3.bucket.name": "kafka-sample-kido-bucket-name",
    "s3.region": "ap-northeast-2",
    "s3.compression.type":"gzip",
    "s3.part.size":5242880,
    "locale":"KR",
    "timezone":"UTC"
}
```

- topics: 데이터를 주고 받은 토픽을 지정한다. 
- tasks.max: 동시 수행할 쓰레드 개수를 지정한다. 여기서는 1로 지정하였다. 
- connector.class: 커넥터의 종유를 나타내며, io.confluent.connect.s3.S3SinkConnector 지정했다. 
- key.converter.schemas.enable: 키 컨버터 스키마를 이용할지 여부 false로 지정
- value.converter.schemas.enable: 값 컨버터 스키마를 이용할지 여부 false로 지정
- key.converter: 키 컨버터 
- value.converter: 값 컨버터
- format.class: 저장소에 키를 쓸 때 사용할 형식 클래스입니다. 가능한 형식은 Avro, Json, ByteArray 및 Parquet입니다
- storage.class: 저장용 클래스 정보를 지정한다. S3Storage 를 지정하였다. 
- partitioner.class: 파티셔너를 구성했다면 지정한다. 기본 파티셔너를 지정했다.
- flush.size: S3에 저장할 플러싱 크기를 지정한다. 파일 커밋을 호출하기 전에 저장하기 위해 기록된 레코드 수를 의미한다.
- s3.bucket.name: S3 버킷 이름이다.
- s3.region: S3의 리젼을 지정한다.
- s3.compression.type: 압축 타입을 지정한다. 여기서는 gzip으로 설정하였다.
- s3.part.size: S3 멀티파트 업로드의 크기를 지정한다. 
- locale: 로케일 지정 KR로 한국으로 지정
- timezone: UTC 타임존으로 지정했다.
- 상세한 정보는 https://docs.confluent.io/kafka-connectors/s3-sink/current/configuration_options.html 에서 확인하자. 

## docker-compose 설정하기. 

- 이제 실제 커넥터를 수행할 docker-compose를 설정해보자. 

### 클러스터 구성 

- 이본 클러스터 구성을 다음과 같이 작성한다. 
- zookeeper, kafka 브로커 설정을 지정한다. 

```yaml
version: '3.8'
services:
  zookeeper-1:
    image: confluentinc/cp-zookeeper:5.5.1
    ports:
      - '32181:32181'
    environment:
      ZOOKEEPER_CLIENT_PORT: 32181
      ZOOKEEPER_TICK_TIME: 2000

  kafka-1:
    image: confluentinc/cp-kafka:5.5.1
    ports:
      - '9092:9092'
    depends_on:
      - zookeeper-1
    volumes:
      - ${PWD}/:/etc/tutorial/      
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper-1:32181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka-1:29092,EXTERNAL://localhost:9092
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_NUM_PARTITIONS: 3

  kafka-2:
    image: confluentinc/cp-kafka:5.5.1
    ports:
      - '9093:9093'
    depends_on:
      - zookeeper-1
    volumes:
      - ${PWD}/:/etc/tutorial/ 
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_ZOOKEEPER_CONNECT: zookeeper-1:32181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka-2:29093,EXTERNAL://localhost:9093
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_NUM_PARTITIONS: 3
    
  kafka-3:
    image: confluentinc/cp-kafka:5.5.1
    ports:
      - '9094:9094'
    depends_on:
      - zookeeper-1
    volumes:
      - ${PWD}/:/etc/tutorial/ 
    environment:
      KAFKA_BROKER_ID: 3
      KAFKA_ZOOKEEPER_CONNECT: zookeeper-1:32181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka-3:29094,EXTERNAL://localhost:9094
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_NUM_PARTITIONS: 3
```

### connect 구성하기

- 커넥터 구성하기
- AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY 를 지정하여 S3 에 접속할 크레덴셜을 환경변수로 등록한다. 

```yaml
  connect:
    hostname: connect
    image: confluentinc/cp-kafka-connect-base:latest
    platform: linux/x86_64
    depends_on:
      - kafka-1
      - kafka-2
      - kafka-3
      - init-kafka
    ports:
      - '8083:8083'
    environment:
      CONNECT_BOOTSTRAP_SERVERS: "kafka-1:29092,kafka-2:29093,kafka-3:29094"
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: kafka-connect
      CONNECT_CONFIG_STORAGE_TOPIC: _connect-configs
      CONNECT_OFFSET_STORAGE_TOPIC: _connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: _connect-status
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: 'true'
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'
      CONNECT_REST_ADVERTISED_HOST_NAME: "kafka-connect"
      CONNECT_LOG4J_APPENDER_STDOUT_LAYOUT_CONVERSIONPATTERN: "[%d] %p %X{connector.context}%m (%c:%L)%n"
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_PLUGIN_PATH: /usr/share
      AWS_ACCESS_KEY_ID: "A___________________O"
      AWS_SECRET_ACCESS_KEY: "4___________________________________________0"
    volumes:
      - ./sample_data:/sample_data
      - ./connector_config:/connector_config
    command:
      - bash
      - -c
      - |
        echo "Installing Connectors"
        confluent-hub install --no-prompt confluentinc/kafka-connect-s3:latest
        #
        echo "Launching Kafka Connect worker"
        /etc/confluent/docker/run &
        #
        # Wait for Kafka Connect listener
        echo "Waiting for Kafka Connect to start listening on localhost"
        while : ; do
          curl_status=$$(curl -s -o /dev/null -w %{http_code} http://localhost:8083/connectors)
          echo -e $$(date) " Kafka Connect listener HTTP state: " $$curl_status " (waiting for 200)"
          if [ $$curl_status -eq 200 ] ; then
            break
          fi
          sleep 5 
        done

        echo -e "\n--\n+> Creating Data Generator source"

        cd /connector_config
        curl -i -X PUT -H Content-Type:application/json http://localhost:8083/connectors/source-loalfile-connector/config -d@connect-file-source.json
        curl -i -X PUT -H Content-Type:application/json http://localhost:8083/connectors/sink-s3-connector/config -d@connect-s3-sink.json
        #

        sleep infinity   
```

#### 커넥터 커맨드로 커넥터 실행하기 

- 카프카 커넥트 s3 플러그인을 설치한다. 

```go
confluent-hub install --no-prompt confluentinc/kafka-connect-s3:latest
```

- 아래와 같이 커넥터를 실행한다. 
  
```go
/etc/confluent/docker/run &
```

- 아래와 같이 connector 가 정상으로 응답하는지 대기하기 위해서 반복하면서 connector의 REST API 를 확인한다. 
  
```go
        while : ; do
          curl_status=$$(curl -s -o /dev/null -w %{http_code} http://localhost:8083/connectors)
          echo -e $$(date) " Kafka Connect listener HTTP state: " $$curl_status " (waiting for 200)"
          if [ $$curl_status -eq 200 ] ; then
            break
          fi
          sleep 5 
        done
```

- 커넥터 등록하기
- 아래와 같이 커넥터 설정정보를 이용하여 커넥터로 등록한다. 
  
```go
      cd /connector_config
      curl -i -X PUT -H Content-Type:application/json http://localhost:8083/connectors/source-loalfile-connector/config -d@connect-file-source.json
      curl -i -X PUT -H Content-Type:application/json http://localhost:8083/connectors/sink-s3-connector/config -d@connect-s3-sink.json
```

### 카프카 초기화

- 카프카 초기화를 아래와 같이 수행한다. 
- 즉 카프카 브로커라 구성이 되면 초기화를 수행하면서 토픽을 생성한다. 

```yaml
  init-kafka:
    image: confluentinc/cp-kafka:latest
    depends_on:
      - kafka-1
      - kafka-2
      - kafka-3
    entrypoint: [ '/bin/sh', '-c' ]
    command: |
      "
      # blocks until kafka is reachable
      kafka-topics --bootstrap-server kafka-1:29092,kafka-2:29093,kafka-3:29094 --list 
      echo -e 'Creating kafka topics'
      kafka-topics --bootstrap-server kafka-1:29092,kafka-2:29093,kafka-3:29094 --create --topic s3-sink-connector
      echo -e 'Successfully created the following topics:'
      kafka-topics --bootstrap-server kafka-1:29092,kafka-2:29093,kafka-3:29094 --list
      sleep infinity
      "        
```

- 내용과 같이 s3-sink-connecto 토픽을 생성했다. 

### kafka-ui 실행하기

```yaml
  kafka-ui:
    image: provectuslabs/kafka-ui
    depends_on:
      - init-kafka
    container_name: kafka-ui
    ports:
      - "8989:8080"
    restart: always
    environment:
      - KAFKA_CLUSTERS_0_NAME=local
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka-1:29092,kafka-2:29093,kafka-3:29094
      - KAFKA_CLUSTERS_0_ZOOKEEPER=zookeeper-1:32181    
```

- 카프카 모니터링을 위해서 kafka-ui 를 구성하였다. 

## 실행하기

```go
$ docker-compose -f docker-compose.yaml up
```

- 위와 같이 docker-compose 를 실행한다. 
- 파일에 지정한 서비스들이 docker-compose 상에 실행이 된다. 

## 결과 확인하기

- kafka-sample-kido-bucket-name 버킷내부에 파일이 생성되었음을 확인할 수 있다. 

## WrapUp

- 위와 같이 파일의 내용을 읽어서 S3로 저장하는 샘플을 확인했다. 
- 커넥터를 생성하고, 소스 커넥터/싱크 커넥터를 등록하였다. 